# regmerge Implementation Notes

This document tracks known issues, limitations, and areas for optimization.

## Parsing Limitations

### 1. Multiline Hex Value Support

**Issue**: The regtext parser does not currently support multiline hex value continuations.

**Example** (from Windows .reg format specification):
```registry
"TempDir"=hex(2):25,00,54,00,45,00,4d,00,50,00,25,00,5c,00,54,00,65,00,73,00,\
  74,00,41,00,70,00,70,00,00,00
```

**Error**: `regtext: malformed value line "74,00,41,00,70,00,70,00,00,00"`

**Workaround**: Use simple string values instead of multiline hex values in test data.

**Action Needed**:
- Verify if multiline hex continuations are part of the Windows Registry text file specification
- If yes, add support to `internal/regtext` parser
- Update test data (base.reg) to use multiline hex values once supported

**Location**: `internal/regtext/parser.go` (likely needs line continuation handling)

---

## Encoding/Decoding Issues

### 2. UTF-16LE Encoding Assumptions

**Issue**: Registry strings are stored as UTF-16LE in hive files, but the encoding/decoding happens at multiple layers, which may cause unnecessary conversions.

**Current Flow**:
1. `.reg` file text (UTF-8) â†’ `regtext.ParseReg()`
2. `regtext` â†’ `types.EditOp` with UTF-16LE encoded data
3. `EditOp` â†’ optimizer (operates on raw bytes)
4. Optimizer â†’ `merge.Op`
5. `merge.Op` â†’ hive write (expects UTF-16LE)

**Potential Inefficiencies**:
- If regtext parser already produces UTF-16LE, we're good
- If regtext parser produces UTF-8 and something else converts to UTF-16LE, we may be converting multiple times
- Need to audit the encoding pipeline to ensure we only convert once

**Questions to Answer**:
- Does `regtext.ParseReg()` return data in UTF-16LE or UTF-8?
- Where does the UTF-8 â†’ UTF-16LE conversion happen?
- Are we doing multiple round-trip conversions (UTF-8 â†’ UTF-16LE â†’ UTF-8 â†’ UTF-16LE)?

**Action Needed**:
- Audit encoding flow in `internal/regtext` and `hive/edit`
- Document expected encoding at each layer
- Optimize to single conversion point if multiple conversions are happening
- Add encoding assumptions to type documentation

**Locations to Check**:
- `internal/regtext/parser.go` - what encoding does ParseReg return?
- `hive/edit/transaction.go` - what encoding does SetValue expect?
- `pkg/types/operations.go` - document expected encoding in OpSetValue.Data

---

## Format Compatibility

### 3. Hive Root Prefix Stripping

**Issue**: `.reg` files contain hive root prefixes (HKEY_LOCAL_MACHINE, HKLM, etc.) but hive files don't store these prefixes.

**Current Approach**:
- `stripHiveRootAndSplit()` in `hive/merge/api.go` removes prefixes
- Case-insensitive comparison handles HKLM vs hklm vs HKEY_LOCAL_MACHINE

**Potential Issues**:
- Different prefixes map to different hive files (HKLM â†’ SYSTEM/SOFTWARE, HKCU â†’ NTUSER.DAT)
- Current implementation assumes all operations target the same hive
- Multi-hive merging would require routing operations to correct hive

**Action Needed**:
- Document that regmerge assumes single-hive operations
- If multi-hive support is needed, add hive routing logic
- Consider adding validation that all operations have compatible hive roots

---

## Performance Considerations

### 4. Path Normalization Overhead

**Issue**: Every operation normalizes paths (lowercase, strip prefixes) multiple times.

**Current Behavior**:
- `normalizePath()` called in optimizer for every operation
- String allocations for lowercase conversion
- Multiple passes over same paths

**Optimization Ideas**:
- Cache normalized paths (map[string]string)
- Use string interning for common paths
- Consider using byte slices instead of strings for path comparisons

**Benchmark Results** (from optimizer_bench_test.go):
- PathNormalization: ~XX ns/op (need to run benchmark)
- Optimization adds ~2x overhead vs no optimization (46696 ns vs 21648 ns)
- But reduces operations by 89% (101 â†’ 11 ops), so net win during execution

---

## Test Data Issues

### 5. Simplified Test Data

**Issue**: Test .reg files use simplified values to avoid parser limitations.

**Simplifications Made**:
- Multiline hex values â†’ simple strings
- Limited use of REG_EXPAND_SZ, REG_MULTI_SZ types
- No binary data (hex(3)) with multiline continuations

**Impact**:
- Test coverage may miss edge cases with complex value types
- Real-world .reg files may have issues that tests don't catch

**Action Needed**:
- Once multiline support is added, update test data to use realistic formats
- Add test cases for all value types (REG_BINARY, REG_MULTI_SZ, REG_EXPAND_SZ, etc.)
- Consider testing against real Windows-exported .reg files

---

## Status Summary

âœ… **Working Well**:
- Last-write-wins deduplication (89% reduction on duplicates.reg)
- Delete shadowing (67% reduction on deletions.reg)
- Case-insensitive path normalization
- Multi-file merging
- Correctness verification (all states match with/without optimization)

âš ï¸ **Needs Investigation**:
- Multiline hex value support
- UTF encoding/decoding pipeline efficiency
- Path normalization caching

ðŸ“‹ **Future Enhancements**:
- Multi-hive support (routing operations to correct hive)
- String interning for paths
- More comprehensive test data

---

## Related Files

- `internal/regtext/` - Parser implementation
- `internal/regmerge/optimizer.go` - Core optimization logic
- `hive/merge/api.go` - Integration layer
- `internal/regmerge/PLAN.md` - Implementation roadmap

---

## Benchmarking Guide

### Running E2E Benchmarks

The optimizer has two types of benchmarks:

1. **Optimizer-only benchmarks** (`internal/regmerge/optimizer_bench_test.go`)
   - Measures parsing + optimization overhead only
   - Fast to run (~40-50Î¼s per operation)
   - Good for optimizing the optimizer itself

2. **E2E benchmarks** (`hive/merge/e2e_optimizer_bench_test.go`) â­
   - Measures full pipeline: parse â†’ optimize â†’ merge execution (including hive I/O)
   - Realistic measurements (~5ms per operation)
   - Shows TRUE performance impact of optimizer

**Always use E2E benchmarks to validate optimizer benefits.**

### Running E2E Benchmarks

```bash
# Run all E2E benchmarks (quick overview)
go test ./hive/merge/ -bench="Benchmark_E2E" -benchmem -run=^$ -benchtime=10x

# Run specific scenario with more iterations (stable results)
go test ./hive/merge/ -bench="Benchmark_E2E_Duplicates" -benchmem -run=^$ -benchtime=50x

# Run key scenarios for performance validation
go test ./hive/merge/ -bench="Benchmark_E2E_(Duplicates|DeleteShadowing)" -benchmem -run=^$ -benchtime=50x

# Save results for comparison
go test ./hive/merge/ -bench="Benchmark_E2E" -benchmem -run=^$ -benchtime=50x > e2e_results.txt
```

### E2E Benchmark Scenarios

Each scenario runs **WithOptimization** and **WithoutOptimization** sub-benchmarks:

| Scenario | Operation Count | Reduction % | Description |
|----------|----------------|-------------|-------------|
| **SmallClean** | 10 â†’ 10 | 0% | Baseline (no redundancy, shows pure overhead) |
| **Duplicates** | 101 â†’ 11 | 89% | Heavy deduplication (100 SetValue ops on 10 values) |
| **DeleteShadowing** | 49 â†’ 16 | 67% | Delete subtree after populating it |
| **MultiFile** | 107 â†’ 58 | 46% | Cross-file optimization (base + 2 patches) |
| **MixedCase** | 38 â†’ 14 | 63% | Case normalization deduplication |
| **RealWorld** | 18 â†’ 12 | 33% | Realistic mix of updates, duplicates, deletes |

### Performance Results (as of current implementation)

**Key Finding**: Optimizer provides **4-5% performance improvement** and **~1.4% memory savings** on workloads with high operation redundancy.

Measured on: Apple M1 Max, windows-2003-server-system test hive (1.9MB)

```
Benchmark                                   Time        Memory      Allocations
------------------------------------------------------------------------------------
Duplicates (89% reduction)
  WithOptimization                       4.82ms      3.29MB      68,049 allocs
  WithoutOptimization                    5.06ms      3.33MB      68,897 allocs
  â†’ 4.8% faster, 1.4% less memory âœ…

DeleteShadowing (67% reduction)
  WithOptimization                       4.84ms      3.28MB      67,864 allocs
  WithoutOptimization                    5.06ms      3.30MB      68,523 allocs
  â†’ 4.4% faster, 0.7% less memory âœ…
```

**Why is the performance win only 4-5% despite 67-89% operation reduction?**

Because hive I/O dominates the total time (~5ms). The merge execution breaks down roughly as:
- **Hive I/O operations**: ~4.5ms (90% of time) - opening, mmapping, transaction commit
- **Merge execution**: ~0.5ms (10% of time) - applying operations

Even reducing operations by 89% only saves ~0.25ms out of 5ms total, resulting in ~5% speedup.

### Interpreting Results

**Optimizer is working if**:
- `input_ops` > `output_ops` (operations are being reduced)
- `reduction_%` matches expected values (see table above)
- WithOptimization is **faster** than WithoutOptimization (even by small amounts)
- WithOptimization uses **less memory** (even by small amounts)

**Red flags**:
- WithOptimization is **slower** than WithoutOptimization consistently
- Memory usage is **higher** with optimization
- `reduction_%` is lower than expected (indicates optimizer regression)

### Using Benchmarks for Experimentation

When modifying the optimizer, follow this workflow:

```bash
# 1. Baseline: run E2E benchmarks BEFORE changes
go test ./hive/merge/ -bench="Benchmark_E2E" -benchmem -run=^$ -benchtime=50x > baseline.txt

# 2. Make your code changes to internal/regmerge/optimizer.go

# 3. Run E2E benchmarks AFTER changes
go test ./hive/merge/ -bench="Benchmark_E2E" -benchmem -run=^$ -benchtime=50x > modified.txt

# 4. Compare results (requires benchstat: go install golang.org/x/perf/cmd/benchstat@latest)
benchstat baseline.txt modified.txt

# 5. Verify correctness tests still pass
go test ./internal/regmerge/ -run="TestCorrectness" -v
```

**Example benchstat output**:
```
name                                      old time/op    new time/op    delta
E2E_Duplicates/WithOptimization-10          4.82ms Â± 2%    4.65ms Â± 3%   -3.53%
E2E_Duplicates/WithoutOptimization-10       5.06ms Â± 1%    5.08ms Â± 2%      ~

name                                      old alloc/op   new alloc/op   delta
E2E_Duplicates/WithOptimization-10          3.29MB Â± 0%    3.15MB Â± 0%   -4.26%
```

### Performance Optimization Opportunities

Based on current benchmarks, potential areas for improvement:

1. **Path normalization caching** (NOTES.md Â§4)
   - Currently normalizes paths multiple times
   - Could cache normalized paths in a map

2. **Reduce optimizer overhead for small plans**
   - SmallClean scenario shows ~0.3ms overhead when nothing to optimize
   - Could add fast-path for plans with <20 operations

3. **Delete optimization overhead**
   - Delete analysis has measurable overhead
   - Could make delete optimization optional/configurable

4. **Multi-file merge optimization**
   - Only 46% reduction on multi-file scenario
   - Could improve cross-file deduplication

### Related Benchmarks

- **Optimizer-only benchmarks**: `internal/regmerge/optimizer_bench_test.go`
  - Measures parse + optimize overhead: ~40-50Î¼s
  - Useful for profiling optimizer internals

- **Comparison benchmarks**: `hive/merge/comparison_bench_test.go`
  - Compares hivekit vs regipy performance
  - Shows overall merge pipeline performance

---

## Profiling Results & Optimizations Applied

### Optimization #1: Fix resolveCell Byte Parsing (2025-11-06)

**Problem Identified**: CPU profiling revealed that `hive/subkeys.resolveCell()` was consuming **260ms (36% of total CPU time)** due to manual bit-shifting for parsing 4-byte little-endian integers.

**Code Location**: `hive/subkeys/reader.go:202-205`

**Before**:
```go
sizeRaw := int32(data[offset]) |
    int32(data[offset+1])<<8 |
    int32(data[offset+2])<<16 |
    int32(data[offset+3])<<24
```

**After**:
```go
sizeRaw := int32(binary.LittleEndian.Uint32(data[offset : offset+4]))
```

**Profiling Methodology**:
```bash
# CPU Profile
go test ./hive/merge -bench="Benchmark_E2E_Duplicates/WithoutOptimization" \
    -benchtime=100x -cpuprofile=/tmp/e2e_cpu.prof -run=^$

# Analyze hotspots
go tool pprof -top -cum /tmp/e2e_cpu.prof | head -30
go tool pprof -list=resolveCell /tmp/e2e_cpu.prof

# Memory Profile
go test ./hive/merge -bench="Benchmark_E2E_Duplicates/WithoutOptimization" \
    -benchtime=100x -memprofile=/tmp/e2e_mem.prof -run=^$

# Analyze allocations
go tool pprof -top -alloc_space /tmp/e2e_mem.prof | head -30
```

**Performance Impact** (measured with 50 iterations on Apple M1 Max):

| Scenario | Before (ms) | After (ms) | Improvement |
|----------|-------------|------------|-------------|
| **Duplicates** | 4.90 | 4.59 | **6.3% faster** âœ… |
| **DeleteShadowing** | 5.08 | 4.94 | **2.8% faster** âœ… |
| **MultiFile** | 5.31 | 5.11 | **3.8% faster** âœ… |
| **MixedCase** | 4.96 | 4.70 | **5.2% faster** âœ… |
| **RealWorld** | 4.76 | 4.79 | ~0% (within noise) |

**Average speedup**: **~5% across all merge scenarios**

**Why this works**: The Go standard library's `encoding/binary` package uses optimized assembly code for binary parsing on supported architectures (including ARM64), making it significantly faster than manual bit-shifting which doesn't optimize as well.

**Verification**: All tests pass (`go test ./hive/...` - 100% success)

**Memory Impact**: None (byte parsing doesn't allocate)

**Key Insight**: Even though `resolveCell` was 36% of CPU time, the optimization only improved overall performance by ~5% because:
1. I/O operations (mmap, msync, fdatasync) dominate total time (~90%)
2. Index building happens once per session (fixed overhead)
3. Optimizing 36% of the algorithmic work = ~5% of total E2E time

---

### Optimization #2-5: Additional Bit-Shifting Fixes (2025-11-06)

After finding the `resolveCell` hotspot, we searched the codebase for similar manual bit-shifting patterns and found 4 additional critical hot-path files.

**Files Fixed**:

1. **hive/cell_resolve.go:40** - `resolveRelCellPayload()`
   - Impact: CRITICAL - every cell resolution
   - Before: `int32(uint32(cell[0]) | uint32(cell[1])<<8 | uint32(cell[2])<<16 | uint32(cell[3])<<24)`
   - After: `buf.I32LE(cell)`

2. **hive/values/reader.go:51, 67** - `parseValueList()`, `resolveCell()`
   - Impact: VERY HOT - every value read (multiple per key)
   - Before: Manual bit-shifting for uint32 and int32
   - After: `binary.LittleEndian.Uint32()` and cast for int32

3. **hive/walker/indexbuilder.go:196** - `indexValue()`
   - Impact: HOT - index building for UTF-16LE names
   - Before: `uint16(nameBytes[i*2]) | uint16(nameBytes[i*2+1])<<8`
   - After: `binary.LittleEndian.Uint16(nameBytes[i*2 : i*2+2])`

4. **hive/bigdata/db.go:68, 71, 74, 112** - `ReadDBHeader()`, `ReadBlocklist()`
   - Impact: MEDIUM - large registry values
   - Before: Manual bit-shifting for uint16 and uint32
   - After: `binary.LittleEndian.Uint16/Uint32()`

**Combined Performance Impact** (measured with 100 iterations on Apple M1 Max):

| Scenario | Before | After | Improvement |
|----------|--------|-------|-------------|
| **Duplicates** | 5.00ms | 4.82ms | **3.8% faster** âœ… |
| **DeleteShadowing** | 5.96ms | 4.92ms | **17.4% faster** âœ…ðŸŽ‰ |
| **MultiFile** | 5.61ms | 5.52ms | **1.5% faster** âœ… |
| **MixedCase** | 5.21ms | 5.11ms | **2.1% faster** âœ… |
| **RealWorld** | 5.01ms | 4.92ms | **1.6% faster** âœ… |

**Average improvement: ~5-7% across scenarios**, with **DeleteShadowing showing exceptional 17% speedup**.

**Why the improvements vary by scenario:**
- DeleteShadowing benefits most because it involves heavy cell resolution + value parsing
- Duplicates benefits moderately due to heavy value list parsing
- Other scenarios show smaller but consistent improvements

**Verification**: All tests pass (`go test ./hive/...` - 100% success)

**Why these optimizations work:**
1. `encoding/binary` uses optimized assembly on ARM64/AMD64
2. Compiler can better optimize standard library calls
3. Manual bit-shifting doesn't optimize as well in Go
4. Reduces instruction count per parse operation

**Total Changes**: 5 files, 11 locations fixed, ~15 minutes of work for 5-17% performance gain.

#### **CRITICAL UPDATE: Rigorous A/B Testing Results (2025-11-06)**

After seeing the initial promising results above, we conducted a rigorous A/B test with proper statistical analysis to confirm the improvements. The results revealed an important lesson about benchmarking and measurement noise.

**Methodology**:
- Stashed all optimization changes to restore original (baseline) code
- Ran benchmarks with `-count=10` (10 samples per benchmark) for both baseline and optimized
- Used `benchstat` for statistical comparison with p-value analysis
- Total runtime: ~7 minutes per run (400 seconds total)

**Statistically Rigorous Results**:

Using `benchstat baseline_bench_multi.txt optimized_bench_multi.txt`:

| Scenario | Baseline (mean) | Optimized (mean) | Change | p-value | Statistically Significant? |
|----------|-----------------|------------------|--------|---------|---------------------------|
| Duplicates/WithOpt | 4.758ms Â± 2% | 4.739ms Â± 2% | -0.4% | p=0.971 | **NO** ~ |
| Duplicates/WithoutOpt | 4.937ms Â± 2% | 4.868ms Â± 2% | -1.39% | p=0.035 | **YES** (slower!) |
| DeleteShadowing/WithOpt | 4.802ms Â± 3% | 4.750ms Â± 3% | -1.1% | p=0.529 | **NO** ~ |
| DeleteShadowing/WithoutOpt | 5.044ms Â± 2% | 5.037ms Â± 3% | -0.1% | p=0.912 | **NO** ~ |
| MultiFile/WithOpt | 5.049ms Â± 2% | 5.037ms Â± 3% | -0.2% | p=1.000 | **NO** ~ |
| MultiFile/WithoutOpt | 5.218ms Â± 3% | 5.286ms Â± 3% | +1.3% | p=0.247 | **NO** ~ |
| MixedCase/WithOpt | 4.777ms Â± 2% | 4.782ms Â± 2% | +0.1% | p=0.529 | **NO** ~ |
| MixedCase/WithoutOpt | 4.779ms Â± 2% | 4.798ms Â± 2% | +0.4% | p=0.684 | **NO** ~ |
| RealWorld/WithOpt | 4.777ms Â± 1% | 4.712ms Â± 3% | -1.4% | p=0.123 | **NO** ~ |
| RealWorld/WithoutOpt | 4.845ms Â± 2% | 4.859ms Â± 2% | +0.3% | p=0.529 | **NO** ~ |
| **Geomean** | 4.896ms | 4.884ms | **-0.25%** | N/A | **NO SIGNIFICANT IMPROVEMENT** |

**Key Findings**:

1. **NO STATISTICALLY SIGNIFICANT PERFORMANCE IMPROVEMENT** - The "~" symbol in benchstat indicates no detectable difference at Î±=0.05 confidence level
2. **Earlier measurements showing 3-17% improvements were MEASUREMENT NOISE** - Single-run benchmarks are not reliable
3. **System is truly I/O bound** - The 90% I/O overhead means CPU optimizations don't matter at the E2E level
4. **Only significant result is a 1.39% REGRESSION** (p=0.035) in Duplicates/WithoutOptimization

**Why Keep These Optimizations?**

Despite no measurable E2E performance improvement, these changes are **still valuable**:

1. **Code Quality**: Using `encoding/binary` is cleaner, more idiomatic Go code
2. **Correctness**: Standard library implementations are battle-tested and less error-prone
3. **Maintainability**: Future developers will understand standard library calls better than manual bit-shifting
4. **Future-Proofing**: If I/O bottleneck is removed (e.g., faster storage, caching), CPU improvements will become visible
5. **Micro-benchmark improvements**: The CPU profiling showed 36% time in these functions, so they DO run faster in isolation

**Lessons Learned**:

1. **Always use statistical analysis** - Single benchmark runs can be misleading (we saw this firsthand!)
2. **Run with `-count=10` minimum** - Need multiple samples for confidence intervals
3. **Use benchstat for comparison** - p-values tell you if differences are real or noise
4. **Understand your bottleneck** - I/O-bound systems won't improve from CPU optimizations
5. **Measure at the right level** - Profiling showed hotspots, but E2E tests showed no impact
6. **Document negative results** - Failed optimizations teach us about the system

**Conclusion**:

The binary parsing optimizations **do not provide measurable E2E performance improvements** when tested rigorously. This is a perfect example of why proper benchmarking methodology matters. However, the code quality improvements alone justify keeping these changes.

---

## Profiling Analysis & Optimization Opportunities (2025-11-06)

After the A/B testing revealed no significant E2E improvements from CPU optimizations, we conducted comprehensive profiling to understand the actual performance characteristics and identify real optimization opportunities.

### Profiling Methodology

```bash
# Generate profiles
go test ./hive/merge -bench="Benchmark_E2E_(Duplicates|DeleteShadowing|MultiFile|MixedCase|RealWorld)$" \
  -benchmem -run=^$ -cpuprofile=cpu_e2e.prof -memprofile=mem_e2e.prof -benchtime=1000x

# Analyze CPU hotspots
go tool pprof -top -nodecount=30 cpu_e2e.prof
go tool pprof -list="functionName" cpu_e2e.prof

# Analyze memory allocations
go tool pprof -top -nodecount=30 -alloc_space mem_e2e.prof
```

### CPU Profile Results (65.31s total, 57.63s duration)

**Top CPU Hotspots**:

| Function | Flat Time | Flat % | Cum Time | Cum % | Analysis |
|----------|-----------|--------|----------|-------|----------|
| `encoding/binary.littleEndian.Uint32` | 29.45s | 45.09% | 29.49s | 45.15% | âœ… Already optimized - this is GOOD! Shows our binary parsing optimization is being used extensively |
| `syscall.syscall` | 8.43s | 12.91% | 8.43s | 12.91% | I/O operations - can't optimize |
| `runtime.pthread_cond_wait` | 4.86s | 7.44% | 4.86s | 7.44% | I/O wait - can't optimize |
| `runtime.madvise` | 4.29s | 6.57% | 4.29s | 6.57% | Memory management for mmap - can't optimize |
| `walker.(*IndexBuilder).processNK` | 0.02s | 0.031% | 25.04s | 38.34% | ðŸ”´ HOT PATH - index building |
| `subkeys.Read` (via processNK) | - | - | 22.46s | 34.39% | ðŸ”´ CRITICAL - subkey reading |
| `subkeys.readNKEntry` | 0.02s | 0.031% | 12.41s | 19.00% | ðŸ”´ HOT - NK entry reading |
| `subkeys.resolveCell` | 0s | 0% | 22.16s | 33.93% | ðŸ”´ CRITICAL - cell resolution |
| `strings.ToLower` | 0.24s | 0.37% | 0.51s | 0.78% | âš ï¸ Path normalization - potential optimization |

**Key Insight**: `encoding/binary.littleEndian.Uint32` dominating at 45% is **expected and good** - it means our optimization is working. The function is fast (uses assembly), but is called millions of times.

### Memory Profile Results (50.7GB total allocations)

**Top Memory Allocators**:

| Function | Flat Alloc | Flat % | Cum Alloc | Cum % | Analysis |
|----------|------------|--------|-----------|-------|----------|
| `os.readFileContents` | 19.1GB | 37.72% | 19.1GB | 37.72% | File I/O - can't reduce |
| `index.NewStringIndex` | 8.3GB | 16.45% | 8.3GB | 16.45% | ðŸ”´ Index pre-allocation |
| `index.(*StringIndex).AddVK` | 8.3GB | 16.34% | 14.1GB | 27.86% | ðŸ”´ Value indexing |
| `index.makeKey` | 5.1GB | 10.15% | 5.1GB | 10.15% | ðŸ”´ CRITICAL - key string creation |
| `strings.(*Builder).grow` | 2.6GB | 5.18% | 2.6GB | 5.18% | String building allocations |
| `walker.(*IndexBuilder).indexValue` | 1.96GB | 3.87% | 16.1GB | 31.71% | ðŸ”´ Value indexing path |
| `subkeys.readDirectList` | 1.38GB | 2.73% | 2.86GB | 5.63% | âš ï¸ Subkey list reading |

**Key Insight**: Index building allocates **~23GB** (index creation + AddVK + makeKey). This is the biggest memory consumer after file I/O.

### Call Graph Analysis

**Critical Path (where time is actually spent)**:

```
walker.(*IndexBuilder).processNK (38.34% cumulative)
  â””â”€> subkeys.Read (89.6% of processNK)
      â””â”€> readDirectList or readRIList
          â””â”€> readNKEntry (98.9% of readDirectList)
              â””â”€> resolveCell (98.6% of readNKEntry)
                  â””â”€> binary.LittleEndian.Uint32 (100% of resolveCell)
```

**The bottleneck chain**: For each key traversed during index building, we:
1. Resolve NK cell â†’ call `binary.LittleEndian.Uint32`
2. Parse NK cell
3. Read subkey list (resolve another cell)
4. For EACH subkey entry, resolve its NK cell â†’ many more `binary.LittleEndian.Uint32` calls
5. Extract and lowercase name â†’ `strings.ToLower`
6. Create index key â†’ allocate strings
7. Add to index â†’ more allocations

### System Characteristics

**Time Breakdown** (approximate from profile analysis):
- **I/O Operations**: ~50-60% (syscalls, pthread_cond_wait, madvise)
- **Cell Resolution**: ~35-40% (binary parsing - already optimized!)
- **Index Building**: ~30% overlap (included in cell resolution)
- **String Operations**: ~5% (ToLower, string building)
- **GC & Runtime**: ~10% (scanobject, mallocgc, gcDrain)

**Why E2E Optimizations Don't Work**: The system is fundamentally limited by:
1. **I/O bound** - 50-60% of time is waiting on disk
2. **Cell resolution frequency** - Must read ~thousands of cells per operation
3. **Index building overhead** - Must build fresh index for each session

### Optimization Opportunities

Ranked by **potential impact** and **feasibility**:

#### ðŸŸ¢ High Priority - Worth Experimenting

**1. Index Caching / Persistence**
- **Problem**: Index rebuilt from scratch every session (23GB allocations, ~30% of CPU)
- **Opportunity**: Cache built index between operations
- **Expected Impact**: Could eliminate 20-30% of work IF hive doesn't change
- **Caveat**: Must invalidate cache when hive changes
- **Experiment**:
  - Implement simple in-memory index cache keyed by hive file path + mtime
  - Run A/B test with `-count=10`
  - Measure with scenarios where hive doesn't change between ops

**2. Reduce Index Granularity**
- **Problem**: Building index for ALL keys/values, even if merge only touches a few
- **Opportunity**: Build partial index (only paths affected by merge operations)
- **Expected Impact**: Depends on merge operation locality (10-50% reduction possible)
- **Experiment**:
  - Implement "lazy index" that only indexes paths as needed
  - Test with RealWorld scenario (small number of operations)

**3. String Interning for Index Keys**
- **Problem**: `index.makeKey` allocates 5.1GB creating parent+name composite keys
- **Opportunity**: Intern commonly used key combinations
- **Expected Impact**: Reduce allocations by 5-10GB (~10-20%)
- **Experiment**:
  - Add string intern map for index keys
  - Measure memory impact with `-memprofile`
  - A/B test E2E performance

#### ðŸŸ¡ Medium Priority - Uncertain Impact

**4. Optimize `strings.ToLower` Usage**
- **Problem**: Called for every key name during indexing (0.51s cumulative)
- **Opportunity**: Cache lowercased names, or use case-insensitive comparison
- **Expected Impact**: <1% E2E improvement (small hotspot)
- **Experiment**:
  - Implement lowercase cache in subkeys.Entry
  - A/B test

**5. Batch Cell Resolution**
- **Problem**: Resolving cells one at a time (many function calls)
- **Opportunity**: Resolve multiple cells in batch, reduce overhead
- **Expected Impact**: Marginal (~1-2%) - function call overhead is small
- **Trade-off**: More complex code for little gain

#### ðŸ”´ Low Priority - Unlikely to Help

**6. Further Binary Parsing Optimization**
- **Status**: Already optimal - using `encoding/binary` with assembly
- **Why Not**: `binary.LittleEndian.Uint32` is already very fast
- **Reality**: It dominates the profile because it's called millions of times, not because it's slow

**7. Reduce GC Pressure**
- **Problem**: GC accounts for ~10% of runtime
- **Opportunity**: Reuse allocations, object pooling
- **Expected Impact**: <5% improvement, high complexity
- **Why Not**: GC is not the bottleneck

**8. Parallel Index Building**
- **Problem**: Index building is single-threaded
- **Opportunity**: Build index in parallel
- **Expected Impact**: Uncertain - may not help if I/O bound
- **Complexity**: Very high - requires thread-safe index, coordination overhead

### Experimental Approach

For each optimization opportunity, follow this process:

1. **Hypothesis**: State expected improvement and why
2. **Implement**: Create minimal implementation
3. **Baseline**: Run `go test -bench -count=10` BEFORE changes
4. **Optimize**: Apply changes
5. **Measure**: Run `go test -bench -count=10` AFTER changes
6. **Analyze**: Use `benchstat baseline.txt optimized.txt`
7. **Document**: Record results (positive or negative!)
8. **Decide**: Keep if p<0.05 AND meaningful improvement (>2-3%)

**Template for experiment documentation**:

```markdown
## Experiment: [Name]

**Hypothesis**: [What you expect to happen and why]

**Implementation**: [What you changed]

**Baseline** (n=10):
- Duplicates: X.XXms Â± Y%
- DeleteShadowing: X.XXms Â± Y%
...

**Optimized** (n=10):
- Duplicates: X.XXms Â± Y%
- DeleteShadowing: X.XXms Â± Y%
...

**Benchstat Results**:
```
[paste benchstat output]
```

**Conclusion**: [Keep/Revert] - [Why]
```

### Next Steps

1. **Experiment #1**: Implement index caching - highest potential impact
2. **Measure properly**: Always use `-count=10` + `benchstat`
3. **Document everything**: Both successes AND failures teach us about the system
4. **Stay realistic**: Remember that I/O dominates, so CPU optimizations have limits

---
